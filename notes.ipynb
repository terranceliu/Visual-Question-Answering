{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets.CIFAR100 as CIFAR100\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tliu/.local/lib/python3.5/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "dataloader = datasets.CIFAR100\n",
    "num_classes = 100\n",
    "\n",
    "img_scale=(256, 256)\n",
    "img_crop=224\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "            transforms.Scale(img_scale),\n",
    "            transforms.CenterCrop(img_crop),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = dataloader(root='./cifar100_data', train=True, download=True, transform=transforms)\n",
    "test_dataloader = dataloader(root='./cifar100_data', train=False, download=True, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.2489,  2.2489,  2.2489,  ...,  0.9303,  0.8789,  0.8447],\n",
       "          [ 2.2489,  2.2489,  2.2489,  ...,  0.9646,  0.9132,  0.8789],\n",
       "          [ 2.2489,  2.2489,  2.2489,  ...,  0.9988,  0.9474,  0.9132],\n",
       "          ...,\n",
       "          [ 0.2453,  0.2453,  0.2282,  ..., -1.4843, -1.3987, -1.3130],\n",
       "          [ 0.1939,  0.2111,  0.1939,  ..., -1.4843, -1.3987, -1.2959],\n",
       "          [ 0.1597,  0.1768,  0.1597,  ..., -1.4843, -1.3815, -1.2788]],\n",
       " \n",
       "         [[ 2.4286,  2.4286,  2.4286,  ...,  1.2206,  1.1856,  1.1681],\n",
       "          [ 2.4286,  2.4286,  2.4286,  ...,  1.2731,  1.2206,  1.2031],\n",
       "          [ 2.4286,  2.4286,  2.4286,  ...,  1.3081,  1.2731,  1.2381],\n",
       "          ...,\n",
       "          [ 1.0455,  1.0455,  1.0455,  ..., -1.5630, -1.4405, -1.3179],\n",
       "          [ 0.9930,  0.9930,  0.9930,  ..., -1.5455, -1.4055, -1.2654],\n",
       "          [ 0.9405,  0.9405,  0.9580,  ..., -1.5280, -1.3704, -1.2304]],\n",
       " \n",
       "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.8971,  0.8274,  0.7576],\n",
       "          [ 2.6400,  2.6400,  2.6400,  ...,  0.9319,  0.8622,  0.7925],\n",
       "          [ 2.6400,  2.6400,  2.6400,  ...,  0.9668,  0.8971,  0.8099],\n",
       "          ...,\n",
       "          [-0.7587, -0.7413, -0.7413,  ..., -1.6999, -1.6650, -1.6127],\n",
       "          [-0.7413, -0.7238, -0.7238,  ..., -1.6824, -1.6302, -1.5779],\n",
       "          [-0.7238, -0.7064, -0.7064,  ..., -1.6650, -1.5953, -1.5430]]]), 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 50\n",
    "num_examples = len(train_dataloader)\n",
    "\n",
    "train_indices = np.random.permutation(num_examples)\n",
    "train_indices = np.split(train_indices, num_users)\n",
    "\n",
    "class CIFAR100Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataloader, indices):\n",
    "        self.dataloader = dataloader\n",
    "        self.indices = indices\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataloader[self.indices[idx]]\n",
    "    \n",
    "datasets = []\n",
    "for i in range(num_users):\n",
    "    datasets.append(CIFAR100Dataset(train_dataloader, train_indices[i]))\n",
    "    \n",
    "dataloaders = []\n",
    "for i in range(num_users):\n",
    "    dataloaders.append(torch.utils.data.DataLoader(datasets[i], batch_size=48, shuffle=True, num_workers=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100Dataset(Dataset):\n",
    "    def __init__(self, dataloader, indices):\n",
    "        self.dataloader = dataloader\n",
    "        self.indices = indices\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataloader[self.indices[idx]]\n",
    "\n",
    "def load_datasets_cifar(config, train=True, img_scale=(256, 256), img_crop=224, download=True, num_users=1):\n",
    "    config = config['data_cifar']\n",
    "    phase = 'train' if train else 'val'\n",
    "    \n",
    "    transforms = transforms.Compose([\n",
    "                transforms.Scale(config['images']['scale']),\n",
    "                transforms.CenterCrop(config['images']['crop']),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    dataloader = dataloader(root=config[dir], train=train, download=True, transform=transforms)\n",
    "    \n",
    "    num_examples = len(dataloader)\n",
    "    indices = np.random.permutation(num_examples)\n",
    "    indices = np.split(indices, num_users)\n",
    "    \n",
    "    datasets = {}\n",
    "    for i in range(num_users):\n",
    "        datasets[i] = CIFAR100Dataset(train_dataloader, train_indices[i])\n",
    "        \n",
    "    dataloaders = {}\n",
    "    for i in range(num_users):\n",
    "        dataloaders[i] = DataLoader(datasets[i], batch_size=config[phase]['batch_size'], shuffle=True, num_workers=config['loader']['workers'])\n",
    "        \n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = False\n",
    "'train' if train else 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
